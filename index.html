<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <link
      href="https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900"
      rel="stylesheet"
    />

    <title>Su Jia's personal webpage</title>
<!--
Reflux Template
https://templatemo.com/tm-531-reflux
-->
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />

    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="assets/css/fontawesome.css" />
    <link rel="stylesheet" href="assets/css/templatemo-style.css" />
    <link rel="stylesheet" href="assets/css/owl.css" />
    <link rel="stylesheet" href="assets/css/lightbox.css" />
  </head>

  <body>
    <div id="page-wraper">
      <!-- Sidebar Menu -->
      <div class="responsive-nav">
        <i class="fa fa-bars" id="menu-toggle"></i>
        <div id="menu" class="menu">
          <i class="fa fa-times" id="menu-close"></i>
          <div class="container">
            <div class="image">
              <a href="#"><img src="photo_su.jpg" alt="" /></a>
            </div>
            <div class="author-content">
              <h1 style="color:White;">Su Jia</h1>
              <span> <h6>  sj693 at cornell.edu </h6></span>
              <span>
              <h7> Office: Rhodes Hall 203, Ithaca, NY </h7></span>
            </div>
            <nav class="main-nav" role="navigation">
              <ul class="main-menu">
                <li><a href="#section1">Bio and CV</a></li>
                <li><a href="#section2">Research Highlights</a></li>
                <li><a href="#section3">Full Publication List</a></li>
                <li><a href="#section4">Contact</a></li>
              </ul>
            </nav>
            <div class="social-network">
              <ul class="soial-icons">
                <li>
                  <a href="https://scholar.google.com/citations?user=tf1c4_kAAAAJ&hl=en"><i class="fa fa-google"></i></a>
                </li>
                <li>
                  <a href="https://www.linkedin.com/in/su-jia-9a2b76b6/"><i class="fa fa-linkedin"></i></a>
                </li>
              </ul>
            </div>
            <div class="copyright-text">
              <p>Copyright 2019 Reflux Design</p>
            </div>
          </div>
        </div>
      </div>

      <section class="section about-me" data-section="section1">
        <div class="container">
          <div class="section-heading">
            <h2>Bio</h2>
            <div class="line-dec"></div>
            <span>
<p align="left"> I am an Assistant Research Professor (non-tenure-track) at the <a target= _blank href="https://datasciencecenter.cornell.edu" > 
Center for Data Science for Enterprise and Society </a> (CDSES), Cornell University. I am interested in data-driven decision-making for business problems. 
More specifically, in terms of methodology, my research is focused on <em>online learning and optimization</em> -- an area that studies how to make informed decisions with a <em>stream</em> of data. In terms of applications,  I am interested in  marketing-related problems, such as advertising, pricing and recommendation.
</p>

<p align="left"> I obtained my PhD degree in the 
	<a target= _blank href="http://aco.math.cmu.edu" > ACO </a> program (Algorithms, Combinatorics and Optimization) from Carnegie Mellon University. I was fortunate to be able to work with
<a target= _blank href="https://www.contrib.andrew.cmu.edu/~ravi/"> R. Ravi</a> and 
<a target= _blank href="https://www.cmu.edu/tepper/faculty-and-research/faculty-by-area/profiles/li-andrew.html"> Andrew Li</a>.
I received my BS degree in Mathematics </a> from Tsinghua University and MS degree in <a target= _blank href="https://www.stonybrook.edu/commcms/ams/" > Applied Maths and Statistics</a>
from Stony Brook University, where I was fortunate to work on computational geometry with
<a target= _blank href="http://www.ams.sunysb.edu/~jsbm/jsbm.html" > Joseph Mitchell</a> and
<a target= _blank href="https://sites.rutgers.edu/jie-gao/about/" > Jie Gao</a>.

<p align="left"> I received the INFORMS Pierskalla Best Paper Award in Health Applications in 2021 and the INFORMS Dantzig Dissertation Award in Operations Research and Management Science in 2022. Here is my <a target= _blank href="CV_SuJia_103122.pdf">CV</a>.
<!-- I have also uploaded my 20-minute <a target= _blank href="https://www.youtube.com/watch?v=Wwh-7KnFOxw">INFORMS talk</a> on Youtube, titled <i> Conservative Price Experimentation: Markdown Pricing Under Unknown Demand </i>. </a> </span> -->
</p> 

  <!-- <p align="left"> Below is a 7-minute video about my recent research:</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/Qz6v-7QgMMg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
    </iframe> -->

  <!-- My research focuses on simplifying operations complexity with customer satisfaction. More precisely, I am interested in (1) the interplay between pricing policy and customer satisfaction, (2) active information acquisition for decision-making, and (3) trading off market opportunities with operations complexity.--> 

</span>
          </div>

     </section>

      <section class="section my-services" data-section="section2">
        <div class="container">
          <div class="section-heading">
            <h2>Research Highlights</h2>
            <div class="line-dec"></div>
            <span
              >The full list of my papers can be found in a separate section.</span>
          </div>

      

          <h5 align='left'> <b>Decision Making Under Smooth Non-stationarity </b> </h5>
            In many applications of online decision making, the environment is non-stationary and it is therefore crucial to use bandit algorithms that handle changes. Most existing approaches are designed to protect against non-smooth changes, constrained only by total variation or Lipschitzness over time. 
            However, in practice environments are often changing smoothly, so such algorithms may incur higher-than-necessary regret in these settings and do not leverage information on the rate of change. 
            <br></br>
             <a target= _blank href="[Jia, Xie, Kallus, Frazier'23]smooth_nonstationary_bandits.pdf"> Smooth Non-stationary Bandits</a> (Under Review)  
             <br> Su Jia, Qian Xie, Nathan Kallus and Peter Frazier.  
          <details>
            <summary>Abstract</summary>
            In many applications of online decision making, the environment is non-stationary and it is therefore crucial to use bandit algorithms that handle changes. Most existing approaches are designed to protect against non-smooth changes, constrained only by total variation or Lipschitzness over time, where they guarantee T^2/3 regret. However, in practice environments are often changing smoothly, so such algorithms may incur higher-than-necessary regret in these settings and do not leverage information on the rate of change. 
            We study a non-stationary two-arm bandit problem where we assume an arm’s mean reward is a &beta;-Holder function over (normalized) time, meaning it is (&beta;- 1)-times Lipschitz-continuously differentiable. We show the first
            separation between the smooth and non-smooth regimes by presenting a policy with  
            T^3/5 regret for &beta; = 2. We complement this result by a T^{(&beta;+1)/(2&beta;+1)} lower bound for any integer &beta; &geq; 1, which matches our upper bound for &beta; = 2.
            <br><b>Key words:</b> non-stationary bandits, Holder class, non-parametric statistics
          </details>  

<hr color= "white">

          <h5 align='left'> <b>Experimental Design for Many Items </b> </h5>
            Modern platforms leverage randomized experiments to make informed decisions from a given set of alternatives. As a particularly challenging scenario, these alternatives can potentially have (i) high volume, with thousands of new items being released each hour, and (ii) short lifetime, either due to the contents’ transient nature, or some underlying non-stationarity that impels the learner to treat the same item as non-identical copies across time.
            <br></br>
             <a target= _blank href="SLHV_bandits_ICML_submission.pdf"> Short-Lived High-Volume Bandits: Algorithms and Field Experiment</a> (Under Review) <br>
             Su Jia, Nishant Oli, Andrew Li, R. Ravi, Paul Duff and Ian Anderson. </p>
          <details>
            <summary>Abstract</summary>
            We consider a multiplay bandits model. In each round a set of k = n^ρ actions that will be available for w rounds arrives, each of whose mean reward is drawn from a fixed known distribution. The learner selects a multiset of n actions at a time. We propose an &ell;-Layered Sieve Policy that recursively refines the action space for &ell; &leq; w times. We show that for any given &rho; > 0, with suitable &ell;, the policy achieves n^-min{&rho;, w/(2w+2)} regret. 
            We also complement this result with an n^−min{&rho;, 1/2} lower bound. Moreover,
            we collaborated with <a target= _blank href="https://www.glance.com"> Glance </a>, India's largest mobile lock-screen content platform, to improve their recommender system for short-lived contents, and showed the effectiveness of our policy in a large-scale field experiment. 
            <br><b>Key words:</b> field experiment, experimental design, short-Lived, high-volume, multi-play bandits, recommender systems
          </details>    
          
<hr color= "white">

      <h5 align='left'> <b>Approximation Algorithms for Active Learning</b></h5>
          In clinical trials, tests are performed sequentially to identify a patient's unknown disease. In marketing, AB tests are performed sequentially to determine the best design of a website. We study the design of low-cost test procedures given a set of tests.  
        <ol>
          <li>
            Unknown Outcomes: <a target= _blank href="https://www.researchgate.net/publication/357753512_Optimal_Decision_Tree_and_Submodular_Function_Ranking_Under_Noisy_Outcomes"> Optimal Decision Tree and Submodular Ranking with Noisy Outcomes. </a> 
            <br> Su Jia, Fatemeh Navidi, Viswanath Nagarajan and R.Ravi. 
            <br> Appeared in NeurIPS'19, journal version under review at JLMR
            <details>
            <summary> Abstract</summary>
            A fundamental task in active learning involves performing a sequence of tests to identify an unknown hypothesis that is drawn from a known distribution. This problem, known as optimal decision tree induction, has been widely studied for decades and the asymptotically best-possible approximation algorithm has been devised for it. We study a generalization where certain test outcomes are noisy, even in the more general case when the noise is persistent, i.e., repeating a test gives the same noisy output, disallowing simple repetition as a way to gain confidence. We design new approximation algorithms for both the non-adaptive setting, where the test sequence must be fixed a-priori, and the adaptive setting where the test sequence depends on the outcomes of prior tests. Previous work in the area assumed at most a logarithmic number of noisy outcomes per hypothesis and provided approximation ratios that depended on parameters such as the minimum probability of a hypothesis. Our new approximation algorithms provide guarantees that are nearly best-possible and work for the general case of a large number of noisy outcomes per test or per hypothesis where the performance degrades smoothly with this number. Our results adapt and generalize methods used for submodular ranking and stochastic set cover. We evaluate the performance of our algorithms on two natural applications with noise: toxic chemical identification and active learning of linear classifiers. Despite our theoretical logarithmic approximation guarantees, our methods give solutions with cost very close to the information theoretic minimum, demonstrating the effectiveness of our methods.
            <br><b>Key words:</b> Optimal Decision Tree, Approximation Algorithms, Submodular Ranking, Stochastic Set Cover
            </details> 
          </li>
            
          <li> 
            Noisy Outcomes: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3894600"> Towards A Liquid Biopsy: Approximation Algorithms for Active Sequential Hypothesis Testing. </a> 
            <br> <b style="color:DarkOrange;"> Winner, INFORMS Pierskalla Best Paper Award 2021 </b> 
            <br> Kyra Gan, Su Jia, Andrew Li and Sridhar Tayur. 
            <br> Appeared in NeurIPS'21, journal version under review  
            <details>
            <summary>Abstract</summary>
            This paper addresses a set of active learning problems that occur in the development of liquid biopsies via the lens of active sequential hypothesis testing (ASHT). In the problem of ASHT, a learner seeks to identify the true hypothesis from among a known set of hypotheses. The learner is given a set of actions and knows the random distribution of the outcome of any action under any true hypothesis. Given a target error &delta; > 0, the goal is to sequentially select the fewest number of actions so as to identify the true hypothesis with probability at least 1 − &delta;. Motivated by applications in which the number of hypotheses or actions is massive (e.g., genomics-based cancer detection), we propose efficient (greedy, in fact) algorithms and provide the first approximation guarantees for ASHT, under two types of adaptivity. Both of our guarantees are independent of the number of actions and logarithmic in the number of hypotheses. We numerically evaluate the performance of our algorithms using both synthetic and real-world DNA mutation data, demonstrating that our algorithms outperform previously proposed heuristic policies by large margins.
            <br><b>Key words:</b> active learning, sequential hypothesis testing, approximation algorithms, cancer detection
            </details> 
          </li>
        </ol>


<hr color= "white">


      <h5 align='left'> <b>Dyanmic Pricing with Monotone Price Sequence</b> </h5>
          In clinical trials, tests are performed sequentially to identify a patient's unknown disease. In marketing, AB tests are performed sequentially to determine the best design of a website. We study the design of low-cost test procedures given a set of tests.
        <ol>
          <li>
            Non-parametric model: <a target= _blank href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3861379"> Conservative Price Experiments: Markdown Pricing Under Unknown Demand. </a> 
            <br> Su Jia, Andrew Li and R. Ravi. 
            <br> <b style="color:DarkOrange;"> Egon Balas Award </b> for best CMU student OR paper, 2020 
            <br> Major Revision, <i>Management Science</i>        
            <details>
            <summary> Abstract</summary>
            We consider the Unimodal Multi-Armed Bandit problem where the goal is to find the optimal price under an unknown unimodal reward function, with an additional "markdown" constraint that requires that the price exploration is non-increasing. This markdown optimization problem faithfully models a single-product revenue management problem where the objective is to adaptively reduce the price over a finite sales horizon to maximize expected revenues.
            We measure the performance of an adaptive exploration-exploitation policy in terms of the regret: the revenue loss relative to the maximum revenue that could have been attained when the demand curve is known in advance. For the case of L-Lipschitz-bounded unimodal revenue functions with infinite inventory, we present a natural policy that explores the price space at a uniform optimal speed in T steps and has regret T^{3/4} (L log T)^{1/4}. 
            On the other side, we provide an almost-matching lower bound of L^{1/4} T^{3/4} on the regret of any policy. Further, under mild assumptions, we show that the above tight bounds also hold when the inventory is finite but is on the order of &Omega;(T). 
            <br> Our tight regret bounds highlight the additional complexity of the markdown constraint, and are asymptotically higher than the corresponding bounds without this markdown requirement of T^{1/2} for unimodal bandits and L^{1/3} T^{2/3} for $L$-Lipschitz bandits. We finally consider a generalization called Dynamic Pricing with Markup Penalty where the seller is allowed to increase the price by paying a markup penalty of magnitude T^c per markup where c&in; [0,1] is a given constant. We extend our results to a tight T^med{2/3, 3/4, c} regret bound for this variant (med{a,b,c} denotes the median of the a,b,c.)
            <br><b>Key words:</b> Markdown Pricing, Multi-armed Bandits, Monotonicity, Unimodal Bandits
            </details> 
          </li>
            
          <li>  
            Parametric model: <a target= _blank href="Markdown_NIPS22_camera_ready_101222.pdf"> Markdown Pricing Under Unknown Parametric Demand Models. </a> <br> Su Jia, Andrew Li and R. Ravi. 
            <br> Appeared in NeurIPS'22, journal version under review  
            <details>
            <summary>Abstract</summary>
            We consider a Continuum-Armed Bandit problem with an additional monotonicity constraint (or “markdown” constraint) on the actions selected. This problem faithfully models a natural revenue management problem, called “markdown pricing”, where the objective is to adaptively reduce the price over a finite horizon to maximize the expected revenues. Prior to this work, a tight T^3/4 regret bound is known under minimal assumptions of unimodality and Lipschitzness in the reward function. This bound shows that markdown pricing is strictly harder than unconstrained dynamic pricing (i.e., without the monotonicity constraint), which admits T^2/3 regret under the same assumptions. However, in practice, demand functions are usually assumed to have certain functional forms (e.g. linear or exponential), rendering the demand learning easier and suggesting better regret bounds. In this work we introduce a concept, markdown dimension, that measures the complexity of a parametric family, and present optimal regret bounds that improve upon the previous T^3/4 bound under this framework.
            <br><b>Key words:</b> markdown pricing, multi-armed bandits, monotonicity, parametric demand model
            </details> 
          </li>
        </ol>

<hr color= "white">


          <h5 align='left'> <b>Omni-Channel Retailing </b></h5>
            Retailers nowadays may use in-store inventory to fulfill the demands from different channels. As opposed to the offline channel, the online channel is more flexible and its orders are fulfilled only periodically. The key problem then is how to jointly manage the orders from these two channels, with consideration of both profit and fulfillment level. We propose a gradient-based computational framework for finding the optimal threshold policy, and demonstrate its effectiveness using Onera's data.
            <br></br>
               <a href = 'https://www.researchgate.net/profile/Su-Jia-11/publication/353447062_Effective_Online_Order_Acceptance_Policies_for_Omni-Channel_Fulfillment/links/60fdab541e95fe241a8a715a/Effective-Online-Order-Acceptance-Policies-for-Omni-Channel-Fulfillment.pdf'>
                  Effective Online Order Acceptance Policies for Omni-Channel Fulfillment. </a> 
                  <br> Su Jia, Jeremy Karp, R. Ravi and Sridhar Tayur. 
                  <br> <i>Manufacturing and Service Operations Management</i>, 2021
             
          <details>
            <summary>Abstract</summary>
            <em>Problem Definition</em>: Omni-channel retailing has led to the use of traditional stores as fulfillment centers for online orders. Omni-channel fulfillment problems have two components: (1) accepting a certain number of on-line orders prior to seeing store demands, and (2) satisfying (or filling) some of these accepted on-line demands as efficiently as possible with any leftover inventory after store demands have been met. Hence, there is a fundamental trade-off between store cancellations of accepted online orders and potentially increased profits due to more acceptances of online orders. We study this joint problem of online order acceptance and fulfillment (including cancellations) to minimize total costs, including shipping charges and cancellation penalties in single-period and limited multi-period settings.
            <br> <em>Academic/Practical Relevance</em>: Despite the growing importance of omni-channel fulfillment via online orders, our work provides the first study incorporating cancellation penalties along with fulfillment costs. 
            <br> <em>Methodology</em>: We build a two-stage stochastic model. In the first stage, the retailer sets a policy specifying which online orders it will accept. The second stage represents the process of fulfilling online orders once the uncertain quantities of in-store purchases are revealed. We analyze two classes of threshold policies that accept online orders as long as the inventories are above a global threshold, or a local threshold per region. 
            <em>Results</em>: Total costs are unimodal as a function of the global threshold, and unimodal as a function of a single local threshold holding all other local thresholds at constant values, motivating a gradient search algorithm. Reformulating as an appropriate linear program with network flow structure, we estimate the derivative (using infinitesimal perturbation analysis) of the total cost as a function of the thresholds. We validate the performance of the threshold policies empirically using data from a high-end North American retailer. Our two-store experiments demonstrate that Local Thresholds perform better than Global Thresholds in a wide variety of settings. Conversely, in a narrow region with negatively correlated online demand between locations and very low shipping costs, Global Threshold outperforms Local Thresholds. A hybrid policy only marginally improves on the better of the two. In multiple periods, we study one- and two-location models and provide insights into effective solution methods for the general case.
            <br> <em>Managerial Implications</em>: Our methods give an effective way to manage fulfillment costs for online orders, demonstrating a significant reduction compared to policies that treat each store separately, reflecting the significant advantage of incorporating shipping in computing thresholds.
            <br><b>Key words:</b> Infinitesimal Perturbation Analsysis (IPA), Fulfillment Policy, Omni-channel retailing
          </details> 

<hr color= "white">


          <h5 align='left'> <b>PhD Thesis</b></h5>
          A large bulk of my work during my Phd focused on developing online learning methodology for operations and marketing problems. Here is a 25-page condensed version of my thesis.  
          <br> 
          <br>  PhD Thesis: 
          <a href = 'thesis_25page_SuJia.pdf'> Learning and Earning Under Noise and Uncertainty. </a> 
          <br>Committee: R. Ravi (Chair), Andrew A. Li, Alan Scheller-Wolf and Sridhar Tayur.
          <br> <b style="color:DarkOrange;"> INFORMS Dantzig Dissertation Award</b>, 2022 
          <br> 
          <details>
            <summary>Abstract</summary>
             Sequential decision-making under uncertainty is central to a range of operations and marketing problems. In the face of an unknown environment, the decision-maker needs to strike a balance between learning the known environment (“learning”) and selecting nearly optimal decisions (“earning”). For instance, consider pricing a new product. If the retailer had full information about the demand at every price level, she could determine and select the revenue-maximizing price for the good. However, such information about the demand curve is typically not available in practice, so the seller needs to experiment with different prices to gain information about the demand curve, and then exploit this information by offering a near-optimal selling price.
             The tradeoff between learning and optimization can be modelled as the Multi-Armed Bandits (MAB) problem, which has attracted significant attention from a range of communities in recent years, including machine learning, operations research and marketing. While most of the fundamental problems in this area have been theoretically well-understood, these algorithms have been rarely deployed in practice. In contrast, while marketing research on sequential decision making has been focused on the practical side, their results are usually empirical and lacking of rigorous analysis.
             This thesis serves as a preliminary step towards filling this gap. We will consider practical sequential decision-making problems arising from some of the most fundamental marketing areas including survey design, pricing and content recommendation, and provide theoretical insights via provable performance guarantees.
          </details> 

      </section>

      <section class="section my-work" data-section="section3">
        <div class="container">
          <div class="section-heading">
            <h2>Full List of Publications and Preprints</h2>
            <span>
           <div class="line-dec"></div>
            <span>

        <li align="left"><a target= _blank href="[Jia, Xie, Kallus, Frazier'23]smooth_nonstationary_bandits.pdf">Smooth Non-stationary Bandits</a> (Submitted) Su Jia, Qian Xie, Nathan Kallus and Peter Frazier</li>
        <li align="left"><a target= _blank href="SLHV_bandits_ICML_submission.pdf">Short-Lived High-Volume Bandit: Algorithms and Field Experiments. </a>  (Submitted) Su Jia, Nishant Oli, Andrew Li, R. Ravi, Paul Duff and Ian Anderson.  </li>
        <li align="left"><a target= _blank href="Markdown_NIPS22_camera_ready_101222.pdf"> Markdown Pricing for Unknown Parametric Demand Models. </a> </br> Su Jia, Andrew Li and R. Ravi. 
        </br> Preliminary version appeared in the proceedings of Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS'22)</li>
        <li align="left"><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3894600"> Toward A Liquid Biopsy: Approximation Algorithms for Adaptive Hypothesis Testing. </a> </br>
        Kyra Gan, Su Jia, Andrew Li and Sridhar Tayur. </br>
        Preliminary version appeared in the proceedings of Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS'21) </br> 
        <b style="color:DarkOrange;"> Winner, INFORMS Pierskalla Best Paper Award 2021 </b> </br> Journal version submitted to <i>Management Science</i></li>
        <li align="left"><a target= _blank href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3861379"> Conservative Price Experimentation: Markdown Pricing with Unknown Demand. </a> </br>
        Su Jia, Andrew Li and R. Ravi. </br>
        <b style="color:DarkOrange;"> Egon Balas Award </b> for best CMU student operations research paper, 2020
        </br> Major revision, <i>Management Science</i></li>
        <li align="left"><a target= _blank href="https://www.researchgate.net/publication/357753512_Optimal_Decision_Tree_and_Submodular_Function_Ranking_Under_Noisy_Outcomes">Optimal Decision Tree and Submodular Ranking with Noisy Outcomes. </a> </br> Su Jia, Fatemeh Navidi, Viswanath Nagarajan and R.Ravi.</br> <a target= _blank href="NIPS19_camera_ready_oct26.pdf">Preliminary version</a> appeared in the proceedings of Thirty-third Conference on Neural Information Processing Systems (NeurIPS'19) </br> Journal version submitted to <i>Operations Research</i></li>
        <li align="left"><a href = 'https://www.researchgate.net/profile/Su-Jia-11/publication/353447062_Effective_Online_Order_Acceptance_Policies_for_Omni-Channel_Fulfillment/links/60fdab541e95fe241a8a715a/Effective-Online-Order-Acceptance-Policies-for-Omni-Channel-Fulfillment.pdf'>
        Effective Online Order Acceptance Policies for Omni-Channel Fulfillment. </a> </br> Su Jia, Jeremy Karp, R. Ravi and  Sridhar Tayur. </br><i>Manufacturing and Service Operations Management (M&SOM)</i> </li>
        <li align="left"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8056969">
        Competitive Analysis for Online Scheduling in Software-Defined Optical WAN. </a></br> Su Jia, Xin Jin, Golnaz Ghasemiesfeh, Jiaxin Ding and Jie Gao. </br> IEEE International Conference on Computer Communications 2017 (INFOCOM’17) </li>
        <li align="left"><a href="https://arxiv.org/pdf/1710.00876.pdf"> Network Optimization on Partitioned Pairs of Points.</a> </br> Esther Arkin, Aritra Banik, Paz Carmi, Gui Citovsky, Su Jia, Matthew Katz, Tyler Mayer and Joseph S. B. Mitchell </br> The 28th International Symposium on Algorithms and Computation (ISAAC'17) </li>
        <li align="left"><a target= _blank href="wrp_with_tlb.pdf" > Geometric Tours to Visit and View Polygons Subject to Time Lower Bounds. (Manuscript) </a></br> Su Jia and Joseph S. B. Mitchell. </li>
        <li align="left"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/11232">Deep Manifold Learning of Symmetric Positive Definite Matrices with Application to Face Recognition. </a> </br> Zhen Dong, Su Jia, Chi Zhang, Tianfu Wu and Mingtao Pei. </br> Thirty-First AAAI Conference on Artificial Intelligence (AAAI'17) </li>
        <li align="left"><a href="http://www.ece.sunysb.edu/~slin/Publications/TWTSP.pdf">Exact and Approximation Algorithms for Time-Window TSP and Prize Collecting Problem.  </a> </br> Su Jia, Jie Gao, Joseph S. B. Mitchell and Lu Zhao.  </br> International Workshop on the Algorithmic Foundations of Robotics 2016 (WAFR'16) </li>
        <li align="left"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/10445">Face Video Retrieval via Deep Learning of Binary Hash Representations. </a> </br> Zhen Dong, Su Jia, Chi Zhang, Tianfu Wu and Mingtao Pei. </br> Thirtieth AAAI Conference on Artificial Intelligence (AAAI'16) </li>
        </ol>
		</span >


      </section>

      <section class="section contact-me" data-section="section4">
        <div class="container">
          <div class="section-heading">
            <h2>Contact </h2>
            <div class="line-dec"></div>
            <span>
              Email: sjia1 at andrew dot cmu dot edu. </p> Office: Tepper Quad 4201.
            </span
            >
          </div>
          <div class="row">
            <div class="right-content">
              <div class="container">
                <form id="contact" action="" method="post">
                  <div class="row">
                    <div class="col-md-6">
                      <fieldset>
                        <input
                          name="name"
                          type="text"
                          class="form-control"
                          id="name"
                          placeholder="Your name..."
                          required=""
                        />
                      </fieldset>
                    </div>
                    <div class="col-md-6">
                      <fieldset>
                        <input
                          name="email"
                          type="text"
                          class="form-control"
                          id="email"
                          placeholder="Your email..."
                          required=""
                        />
                      </fieldset>
                    </div>
                    <div class="col-md-12">
                      <fieldset>
                        <input
                          name="subject"
                          type="text"
                          class="form-control"
                          id="subject"
                          placeholder="Subject..."
                          required=""
                        />
                      </fieldset>
                    </div>
                    <div class="col-md-12">
                      <fieldset>
                        <textarea
                          name="message"
                          rows="6"
                          class="form-control"
                          id="message"
                          placeholder="Your message..."
                          required=""
                        ></textarea>
                      </fieldset>
                    </div>
                    <div class="col-md-12">
                      <fieldset>
                        <button type="submit" id="form-submit" class="button">
                          Send Message
                        </button>
                      </fieldset>
                    </div>
                  </div>
                </form>
              </div>
            </div>
          </div>
        </div>
      </section>
    </div>

    <!-- Scripts -->
    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <script src="assets/js/isotope.min.js"></script>
    <script src="assets/js/owl-carousel.js"></script>
    <script src="assets/js/lightbox.js"></script>
    <script src="assets/js/custom.js"></script>
    <script>
      //according to loftblog tut
      $(".main-menu li:first").addClass("active");

      var showSection = function showSection(section, isAnimate) {
        var direction = section.replace(/#/, ""),
          reqSection = $(".section").filter(
            '[data-section="' + direction + '"]'
          ),
          reqSectionPos = reqSection.offset().top - 0;

        if (isAnimate) {
          $("body, html").animate(
            {
              scrollTop: reqSectionPos
            },
            800
          );
        } else {
          $("body, html").scrollTop(reqSectionPos);
        }
      };

      var checkSection = function checkSection() {
        $(".section").each(function() {
          var $this = $(this),
            topEdge = $this.offset().top - 80,
            bottomEdge = topEdge + $this.height(),
            wScroll = $(window).scrollTop();
          if (topEdge < wScroll && bottomEdge > wScroll) {
            var currentId = $this.data("section"),
              reqLink = $("a").filter("[href*=\\#" + currentId + "]");
            reqLink
              .closest("li")
              .addClass("active")
              .siblings()
              .removeClass("active");
          }
        });
      };

      $(".main-menu").on("click", "a", function(e) {
        e.preventDefault();
        showSection($(this).attr("href"), true);
      });

      $(window).scroll(function() {
        checkSection();
      });
    </script>
  </body>
</html>
